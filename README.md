# ğŸš€ POC â€“ Spring AI com RAG (Retrieval-Augmented Generation)

Este repositÃ³rio apresenta uma **Prova de Conceito (POC)** para exploraÃ§Ã£o de **IA Generativa com Spring AI**, evoluindo de uma interaÃ§Ã£o simples com LLM atÃ© uma arquitetura completa com **RAG** e **Vector Store (Qdrant)**.

O objetivo Ã© demonstrar, de forma incremental, como construir aplicaÃ§Ãµes corporativas modernas utilizando **LLMs**, **memÃ³ria conversacional**, **persistÃªncia relacional** e **busca vetorial**.

---

## ğŸ§ª EvoluÃ§Ã£o das Provas de Conceito

### ğŸ”¹ POC 1 â€“ InteraÃ§Ã£o BÃ¡sica com LLM
- Primeira iteraÃ§Ã£o com um **Large Language Model (LLM)**
- Envio de prompts simples
- Respostas diretas sem memÃ³ria ou contexto persistente

---

### ğŸ”¹ POC 2 â€“ PersistÃªncia de HistÃ³rico de Conversas
- EvoluÃ§Ã£o para uma aplicaÃ§Ã£o com **banco de dados relacional**
- Armazenamento do histÃ³rico de conversas
- IntroduÃ§Ã£o de **memÃ³ria conversacional**
- Base para auditoria e continuidade de diÃ¡logos

---

### ğŸ”¹ POC 3 â€“ RAG com Vector Store (Qdrant)
- ImplementaÃ§Ã£o de **Retrieval-Augmented Generation (RAG)**
- IntegraÃ§Ã£o com **Qdrant** como banco vetorial
- Busca semÃ¢ntica baseada em embeddings
- Respostas enriquecidas com **contexto privado** relevante
- **Contexto privado** que empresas e organizaÃ§Ãµes precisam ***sem expor*** seus dados ao mundo externo.

---

## ğŸ§  Contexto â€“ Spring AI

As POCs foram desenvolvidas e validadas utilizando os principais componentes do **Spring AI**, explorando:

### VisÃ£o Geral
#### Diagrama de Contexto do C4 (Nivel 1)

![Texto alternativo](https://github.com/alexandreximenes/ai/blob/main/img/use-case-ia-0.png)

### VisÃ£o Detalhe
#### Diagrama de Container do C4 (Nivel 2)

![Texto alternativo](https://github.com/alexandreximenes/ai/blob/main/img/use-case-ia-2.png)

![Spring AI Overview](https://github.com/alexandreximenes/ai/blob/main/img/spring-ai.png)

---

## ğŸ”„ Fluxo de InteraÃ§Ã£o com o AI Provider

A imagem abaixo demonstra o fluxo completo desde a **entrada do usuÃ¡rio**, passando pelo **processamento da aplicaÃ§Ã£o**, atÃ© a **resposta do AI Provider**.

![Fluxo de InteraÃ§Ã£o](https://github.com/alexandreximenes/ai/blob/main/img/use-case-ia-1.png)

---

## ğŸ§© Casos de Uso

### VisÃ£o Geral
#### Diagrama de Contexto do C4 (Nivel 1)

![Casos de Uso](https://github.com/alexandreximenes/ai/blob/main/img/use-case-ia-0.png)

---

### ğŸ› ï¸ AplicaÃ§Ã£o Web Admin
ResponsÃ¡vel pela **administraÃ§Ã£o e governanÃ§a da IA**, incluindo:
- ConfiguraÃ§Ã£o de parÃ¢metros de inferÃªncia (tokens, temperatura, etc.)
- Envio e ingestÃ£o de documentos
- Gerenciamento do banco vetorial
- PreparaÃ§Ã£o de dados para RAG

---

### ğŸ’¬ AplicaÃ§Ã£o Chat (Prompt)
Interface voltada ao **usuÃ¡rio final**, permitindo:
- Envio de prompts
- InteraÃ§Ã£o direta com o LLM
- Respostas contextualizadas (RAG)
- Continuidade conversacional

---

### VisÃ£o Detalhe
#### Diagrama de Container do C4 (Nivel 2) do backend

![Casos de Uso](https://github.com/alexandreximenes/ai/blob/main/img/use-case-ia-2.png)

---

## ğŸ” VisÃµes Detalhadas

### ğŸ“Œ AplicaÃ§Ã£o Web Admin â€“ VisÃ£o Ampliada
![Admin App](https://github.com/alexandreximenes/ai/blob/main/img/use-case-ia-3.png)

### ğŸ“Œ AplicaÃ§Ã£o Chat â€“ VisÃ£o Ampliada
![Chat App](https://github.com/alexandreximenes/ai/blob/main/img/use-case-ia-4.png)

---

## ğŸ§  POC 3 â€“ ImplementaÃ§Ã£o de RAG

### ğŸ“– VisÃ£o Geral da Arquitetura RAG
Demonstra o fluxo completo de:
- IngestÃ£o de documentos
- GeraÃ§Ã£o de embeddings
- Armazenamento no Vector Store
- RecuperaÃ§Ã£o de contexto relevante
- GeraÃ§Ã£o de respostas enriquecidas

![RAG Overview](https://github.com/alexandreximenes/ai/blob/main/img/rag-1-a.png)

---

### ğŸ” VisÃ£o Detalhada do Processo RAG
Fluxo detalhado da interaÃ§Ã£o entre:
- Prompt do usuÃ¡rio
- Busca vetorial
- ContextualizaÃ§Ã£o
- Resposta final do LLM

![RAG Detailed](https://github.com/alexandreximenes/ai/blob/main/img/rag-2-b.png)

---

## ğŸ§  POC 4 â€“ ImplementaÃ§Ã£o de Tools
ğŸ“Œ Objetivo

Permitir que o LLM vÃ¡ alÃ©m do conhecimento estÃ¡tico de treinamento, integrando fontes de dados externas, sistemas internos e serviÃ§os corporativos para gerar respostas contextualizadas, atualizadas e acionÃ¡veis.

### ğŸ§© Conceito de Tools (Function Calling / Tool Calling)

Tools sÃ£o funÃ§Ãµes/serviÃ§os que o LLM pode invocar dinamicamente durante a conversa para:

- Consultar APIs
- Acessar bancos de dados
- Executar regras de negÃ³cio
- Buscar dados em sistemas legados
- Consultar serviÃ§os externos (clima, ERP, CRM, pagamentos, etc.)
- O LLM nÃ£o apenas responde â€” ele orquestra fluxos de execuÃ§Ã£o.

![Texto alternativo](https://github.com/alexandreximenes/ai/blob/main/img/tools-1.png)

### ğŸ” Fluxo de Funcionamento

- UsuÃ¡rio envia a pergunta
- LLM interpreta a intenÃ§Ã£o
- LLM decide se precisa de uma Tool
- Tool Ã© chamada automaticamente
- Sistema executa a funÃ§Ã£o
- Resultado retorna ao LLM
- LLM gera resposta final enriquecida

---

## ğŸ“Œ Tecnologias Envolvidas
- **Java / Spring Boot**
- **Spring AI**
- **LLMs (via AI Provider)**
- **Qdrant (Vector Store)**
- **Banco de Dados Relacional**
- **Docker / Docker Compose**

---

## ğŸ¯ Objetivo Final
Demonstrar como arquitetar soluÃ§Ãµes de **IA Generativa corporativas**, escalÃ¡veis e observÃ¡veis, utilizando **Spring AI**, com foco em:
- Qualidade de respostas
- ReduÃ§Ã£o de alucinaÃ§Ãµes
- Uso eficiente de contexto
- EvoluÃ§Ã£o incremental da arquitetura

